{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0c53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.metrics import hamming_loss, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e8fb6a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1fc6db4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "def load_and_preprocess_data(file_path):\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Print dataset info\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"First 5 rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nColumn information:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"\\nMissing values:\\n\", missing_values)\n",
    "\n",
    "    # If there are missing values, fill them\n",
    "    if missing_values.sum() > 0:\n",
    "        print(\"Filling missing values...\")\n",
    "        # For numeric features, fill with median\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        for col in numeric_cols:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "        # For categorical features, fill with mode\n",
    "        cat_cols = df.select_dtypes(include=['object']).columns\n",
    "        for col in cat_cols:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    # Identify feature columns and target columns\n",
    "    # We're assuming the last few columns are the defect labels\n",
    "    # Adjust this based on your actual dataset structure\n",
    "\n",
    "    # Example approach - modify as needed for your dataset\n",
    "    # Assuming binary classification labels are at the end of the dataframe\n",
    "    # and feature columns come before them\n",
    "    # This is an assumption - you'll need to adapt this to your actual data structure\n",
    "\n",
    "    # Check for columns that look like labels (binary values with 0 and 1)\n",
    "    potential_label_cols = []\n",
    "    for col in df.columns:\n",
    "        unique_vals = df[col].unique()\n",
    "        if set(unique_vals).issubset({0, 1, 0.0, 1.0}) and len(unique_vals) <= 2:\n",
    "            potential_label_cols.append(col)\n",
    "\n",
    "    # If we found potential label columns, use them as targets\n",
    "    # Otherwise, assume the last quarter of columns are label columns\n",
    "    if len(potential_label_cols) > 1:  # Assuming multiple label columns\n",
    "        label_columns = potential_label_cols\n",
    "        feature_columns = [col for col in df.columns if col not in label_columns]\n",
    "    else:\n",
    "        # If we couldn't identify label columns, guess\n",
    "        n_cols = df.shape[1]\n",
    "        feature_end_idx = int(0.75 * n_cols)  # Assuming last 25% are labels\n",
    "        feature_columns = df.columns[:feature_end_idx]\n",
    "        label_columns = df.columns[feature_end_idx:]\n",
    "\n",
    "    print(f\"\\nFeature columns ({len(feature_columns)}):\", feature_columns[:5], \"...\")\n",
    "    print(f\"Label columns ({len(label_columns)}):\", label_columns)\n",
    "\n",
    "    # Check label distribution\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    for col in label_columns:\n",
    "        print(f\"{col}: {df[col].value_counts()}\")\n",
    "\n",
    "    # Check for imbalanced labels\n",
    "    imbalance_ratios = []\n",
    "    for col in label_columns:\n",
    "        try:\n",
    "            ratio = df[col].value_counts()[1] / df[col].value_counts()[0]\n",
    "            imbalance_ratios.append((col, ratio))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(\"\\nImbalance ratios (positive/negative):\")\n",
    "    for col, ratio in imbalance_ratios:\n",
    "        print(f\"{col}: {ratio:.4f}\")\n",
    "\n",
    "    # Process text features using TF-IDF\n",
    "    print(\"\\nProcessing text features...\")\n",
    "    text_features = df['report'].values\n",
    "\n",
    "    # Convert text to numerical features using TF-IDF\n",
    "    vectorizer = TfidfVectorizer(max_features=100)  # Limit to 100 features for simplicity\n",
    "    X_text = vectorizer.fit_transform(text_features)\n",
    "\n",
    "    # Convert sparse matrix to dense array for PyTorch compatibility\n",
    "    X_text = X_text.toarray()\n",
    "\n",
    "    # Save the vectorizer for later use\n",
    "    joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "    # Extract labels\n",
    "    y = df[label_columns].values\n",
    "\n",
    "    print(f\"Features shape after TF-IDF: {X_text.shape}\")\n",
    "    print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "    return X_text, y, label_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33ec642",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset for multi-label classification\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e626b9e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define DNN model for multi-label classification\n",
    "class MultiLabelDNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes=[256, 128]):\n",
    "        super(MultiLabelDNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_sizes[1], output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b168c60c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Train DNN model\n",
    "def train_dnn_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=15, device='cpu'):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_hamming_loss': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Convert to binary predictions\n",
    "                preds = (outputs > 0.5).float()\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "        val_hamming = hamming_loss(np.array(val_labels), np.array(val_preds))\n",
    "\n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['val_hamming_loss'].append(val_hamming)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "              f'Val Loss: {val_loss/len(val_loader):.4f}, Val Hamming Loss: {val_hamming:.4f}')\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_multilabel_dnn_model.pth')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df0779d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Evaluate model with multi-label metrics\n",
    "def evaluate_multilabel_model(y_true, y_pred):\n",
    "    metrics = {\n",
    "        'hamming_loss': hamming_loss(y_true, y_pred),\n",
    "        'micro_f1': f1_score(y_true, y_pred, average='micro'),\n",
    "        'macro_f1': f1_score(y_true, y_pred, average='macro')\n",
    "    }\n",
    "\n",
    "    # Calculate precision@k\n",
    "    def precision_at_k(y_true, y_pred, k):\n",
    "        # For each sample, get the top k predicted labels\n",
    "        n_samples = y_true.shape[0]\n",
    "        total_precision = 0\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            # Get indices of top k predictions\n",
    "            top_k_indices = np.argsort(y_pred[i])[-k:]\n",
    "\n",
    "            # Count how many of them are true positives\n",
    "            true_positives = np.sum(y_true[i, top_k_indices])\n",
    "\n",
    "            # Calculate precision@k for this sample\n",
    "            precision = true_positives / k if k > 0 else 0\n",
    "            total_precision += precision\n",
    "\n",
    "        # Return average precision@k across all samples\n",
    "        return total_precision / n_samples if n_samples > 0 else 0\n",
    "\n",
    "    # Calculate precision@k for k=1, 3, 5 (if applicable)\n",
    "    n_labels = y_true.shape[1]\n",
    "    for k in [1, min(3, n_labels), min(5, n_labels)]:\n",
    "        metrics[f'precision@{k}'] = precision_at_k(y_true, y_pred, k)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68e13328",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Online Perceptron with partial_fit\n",
    "class OnlinePerceptron:\n",
    "    def __init__(self, n_features, n_labels):\n",
    "        self.perceptrons = [Perceptron(alpha=0.01) for _ in range(n_labels)]\n",
    "        self.n_features = n_features\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize each perceptron with a single example\n",
    "        for i, perceptron in enumerate(self.perceptrons):\n",
    "            perceptron.partial_fit(X[:1], y[:1, i], classes=[0, 1])\n",
    "\n",
    "        # Train each perceptron online\n",
    "        for j in range(1, len(X)):\n",
    "            self.partial_fit(X[j:j+1], y[j:j+1])\n",
    "\n",
    "            if j % 100 == 0:\n",
    "                print(f\"Processed {j} samples\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y):\n",
    "        for i, perceptron in enumerate(self.perceptrons):\n",
    "            perceptron.partial_fit(X, y[:, i], classes=[0, 1])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros((X.shape[0], self.n_labels))\n",
    "        for i, perceptron in enumerate(self.perceptrons):\n",
    "            y_pred[:, i] = perceptron.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # This is a rough approximation since Perceptron doesn't have predict_proba\n",
    "        # We're using the decision function output and transforming to [0,1]\n",
    "        y_pred = np.zeros((X.shape[0], self.n_labels))\n",
    "        for i, perceptron in enumerate(self.perceptrons):\n",
    "            try:\n",
    "                # Get decision function values\n",
    "                decisions = perceptron.decision_function(X)\n",
    "                # Transform to pseudo-probabilities with sigmoid\n",
    "                y_pred[:, i] = 1 / (1 + np.exp(-decisions))\n",
    "            except:\n",
    "                # Fallback to binary predictions\n",
    "                y_pred[:, i] = perceptron.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870e186a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss over epochs')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['val_hamming_loss'], label='Validation Hamming Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Hamming Loss over epochs')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('multilabel_training_history.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e84d41",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Compare models\n",
    "def compare_multilabel_models(results):\n",
    "    models = list(results.keys())\n",
    "    metrics = ['hamming_loss', 'micro_f1', 'macro_f1', 'precision@1']\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        values = [results[model][metric] for model in models]\n",
    "        plt.bar(models, values)\n",
    "        plt.title(f'Comparison of {metric}')\n",
    "\n",
    "        # For hamming loss, lower is better\n",
    "        if metric == 'hamming_loss':\n",
    "            plt.ylim(0, min(1.0, max(values) * 1.2))\n",
    "        else:\n",
    "            plt.ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('multilabel_model_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Also show as a table\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(df_results)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a92a8d2e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Starting multi-label defect prediction...\")\n",
    "\n",
    "    # Create synthetic data instead of loading from file\n",
    "    print(\"Creating synthetic data for multi-label classification...\")\n",
    "\n",
    "    # Generate synthetic features and labels\n",
    "    n_samples = 500\n",
    "    n_features = 100\n",
    "    n_labels = 7\n",
    "\n",
    "    # Generate random features\n",
    "    X = np.random.rand(n_samples, n_features)\n",
    "\n",
    "    # Generate random binary labels\n",
    "    y = np.random.randint(0, 2, size=(n_samples, n_labels))\n",
    "\n",
    "    # Create label column names\n",
    "    label_columns = [f'label_{i}' for i in range(n_labels)]\n",
    "\n",
    "    print(f\"Synthetic data created: {n_samples} samples with {n_features} features and {n_labels} labels\")\n",
    "    print(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "\n",
    "    if X is None or y is None:\n",
    "        print(\"Error: Dataset processing failed.\")\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        n_features = X.shape[1]\n",
    "        n_labels = y.shape[1]\n",
    "\n",
    "        print(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "\n",
    "        # Split data\n",
    "        print(\"Splitting data into train/validation/test sets...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "        # Standardize features\n",
    "        print(\"Standardizing features...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        print(\"Feature standardization complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data preparation: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, 'defect_feature_scaler.pkl')\n",
    "\n",
    "    # Save label columns for reference\n",
    "    with open('defect_label_columns.txt', 'w') as f:\n",
    "        for col in label_columns:\n",
    "            f.write(f\"{col}\\n\")\n",
    "\n",
    "    # Train traditional models\n",
    "    results = {}\n",
    "\n",
    "   # 1. Logistic Regression (One-vs-Rest)\n",
    "    print(\"\\n1. Training Logistic Regression (One-vs-Rest)...\")\n",
    "    lr = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    y_pred_lr = lr.predict(X_test_scaled)\n",
    "    results['logistic_regression'] = evaluate_multilabel_model(y_test, y_pred_lr)\n",
    "    print(\"Logistic Regression metrics:\", results['logistic_regression'])\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(lr, 'lr_defect_model.pkl')\n",
    "\n",
    "    # 2. SVM (One-vs-Rest)\n",
    "    print(\"\\n2. Training SVM (One-vs-Rest)...\")\n",
    "    svm = MultiOutputClassifier(SVC(probability=True))\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    y_pred_svm = svm.predict(X_test_scaled)\n",
    "    results['svm'] = evaluate_multilabel_model(y_test, y_pred_svm)\n",
    "    print(\"SVM metrics:\", results['svm'])\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(svm, 'svm_defect_model.pkl')\n",
    "\n",
    "    # 3. Standard Perceptron (One-vs-Rest)\n",
    "    print(\"\\n3. Training Standard Perceptron (One-vs-Rest)...\")\n",
    "    perceptron = MultiOutputClassifier(Perceptron(max_iter=1000))\n",
    "    perceptron.fit(X_train_scaled, y_train)\n",
    "    y_pred_perceptron = perceptron.predict(X_test_scaled)\n",
    "    results['perceptron'] = evaluate_multilabel_model(y_test, y_pred_perceptron)\n",
    "    print(\"Perceptron metrics:\", results['perceptron'])\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(perceptron, 'perceptron_defect_model.pkl')\n",
    "\n",
    "    # 4. Online Learning Perceptron (Challenge Element)\n",
    "    print(\"\\n4. Training Online Learning Perceptron...\")\n",
    "    online_perceptron = OnlinePerceptron(n_features, n_labels)\n",
    "    online_perceptron.fit(X_train_scaled, y_train)\n",
    "    y_pred_online = online_perceptron.predict(X_test_scaled)\n",
    "    results['online_perceptron'] = evaluate_multilabel_model(y_test, y_pred_online)\n",
    "    print(\"Online Perceptron metrics:\", results['online_perceptron'])\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(online_perceptron, 'online_perceptron_defect_model.pkl')\n",
    "\n",
    "    # 5. Deep Neural Network\n",
    "    print(\"\\n5. Training Deep Neural Network...\")\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataset = MultiLabelDataset(X_train_scaled, y_train)\n",
    "    val_dataset = MultiLabelDataset(X_val_scaled, y_val)\n",
    "    test_dataset = MultiLabelDataset(X_test_scaled, y_test)\n",
    "\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize DNN\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    dnn_model = MultiLabelDNN(n_features, n_labels)\n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy Loss for multi-label\n",
    "    optimizer = optim.Adam(dnn_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train DNN\n",
    "    history = train_dnn_model(dnn_model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device=device)\n",
    "\n",
    "    # Plot training history\n",
    "    plot_history(history)\n",
    "\n",
    "    # Load best model\n",
    "    dnn_model.load_state_dict(torch.load('best_multilabel_dnn_model.pth'))\n",
    "    dnn_model.to(device)\n",
    "\n",
    "    # Evaluate DNN on test set\n",
    "    dnn_model.eval()\n",
    "    y_pred_dnn = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = dnn_model(X_batch)\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            y_pred_dnn.extend(preds)\n",
    "\n",
    "    y_pred_dnn = np.array(y_pred_dnn)\n",
    "    results['dnn'] = evaluate_multilabel_model(y_test, y_pred_dnn)\n",
    "    print(\"DNN metrics:\", results['dnn'])\n",
    "\n",
    "    # Compare all models\n",
    "    print(\"\\nComparing all models:\")\n",
    "    results_df = compare_multilabel_models(results)\n",
    "\n",
    "    # Save results\n",
    "    results_df.to_csv('defect_prediction_results.csv')\n",
    "\n",
    "    print(\"All models trained and evaluated!\")\n",
    "    return results_df, n_features, n_labels  # Return dimensions for later use in the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131b3636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-label defect prediction...\n",
      "Creating synthetic data for multi-label classification...\n",
      "Synthetic data created: 500 samples with 100 features and 7 labels\n",
      "Features shape: (500, 100), Labels shape: (500, 7)\n",
      "Features shape: (500, 100), Labels shape: (500, 7)\n",
      "Splitting data into train/validation/test sets...\n",
      "Standardizing features...\n",
      "Feature standardization complete.\n",
      "\n",
      "1. Training Logistic Regression (One-vs-Rest)...\n",
      "Logistic Regression metrics: {'hamming_loss': 0.5114285714285715, 'micro_f1': 0.5, 'macro_f1': 0.4975318760987129, 'precision@1': np.float64(0.54), 'precision@3': np.float64(0.48666666666666664), 'precision@5': np.float64(0.5119999999999998)}\n",
      "\n",
      "2. Training SVM (One-vs-Rest)...\n",
      "SVM metrics: {'hamming_loss': 0.4942857142857143, 'micro_f1': 0.5234159779614325, 'macro_f1': 0.5177443094251182, 'precision@1': np.float64(0.52), 'precision@3': np.float64(0.5033333333333334), 'precision@5': np.float64(0.5219999999999999)}\n",
      "\n",
      "3. Training Standard Perceptron (One-vs-Rest)...\n",
      "Perceptron metrics: {'hamming_loss': 0.49857142857142855, 'micro_f1': 0.5118881118881119, 'macro_f1': 0.5090352857056711, 'precision@1': np.float64(0.59), 'precision@3': np.float64(0.5066666666666667), 'precision@5': np.float64(0.5119999999999998)}\n",
      "\n",
      "4. Training Online Learning Perceptron...\n",
      "Processed 100 samples\n",
      "Processed 200 samples\n",
      "Online Perceptron metrics: {'hamming_loss': 0.5242857142857142, 'micro_f1': 0.4823695345557123, 'macro_f1': 0.4791967608131494, 'precision@1': np.float64(0.54), 'precision@3': np.float64(0.4699999999999999), 'precision@5': np.float64(0.4879999999999996)}\n",
      "\n",
      "5. Training Deep Neural Network...\n",
      "Using device: cpu\n",
      "Epoch 1/20, Train Loss: 0.6967, Val Loss: 0.6915, Val Hamming Loss: 0.4843\n",
      "Epoch 2/20, Train Loss: 0.6824, Val Loss: 0.6958, Val Hamming Loss: 0.5171\n",
      "Epoch 3/20, Train Loss: 0.6741, Val Loss: 0.6940, Val Hamming Loss: 0.5243\n",
      "Epoch 4/20, Train Loss: 0.6577, Val Loss: 0.6952, Val Hamming Loss: 0.5186\n",
      "Epoch 5/20, Train Loss: 0.6431, Val Loss: 0.6984, Val Hamming Loss: 0.5071\n",
      "Epoch 6/20, Train Loss: 0.6222, Val Loss: 0.7007, Val Hamming Loss: 0.4943\n",
      "Epoch 7/20, Train Loss: 0.6022, Val Loss: 0.7125, Val Hamming Loss: 0.5114\n",
      "Epoch 8/20, Train Loss: 0.5778, Val Loss: 0.7253, Val Hamming Loss: 0.5243\n",
      "Epoch 9/20, Train Loss: 0.5470, Val Loss: 0.7369, Val Hamming Loss: 0.5014\n",
      "Epoch 10/20, Train Loss: 0.5167, Val Loss: 0.7580, Val Hamming Loss: 0.5043\n",
      "Epoch 11/20, Train Loss: 0.4974, Val Loss: 0.7825, Val Hamming Loss: 0.5071\n",
      "Epoch 12/20, Train Loss: 0.4692, Val Loss: 0.8031, Val Hamming Loss: 0.4929\n",
      "Epoch 13/20, Train Loss: 0.4322, Val Loss: 0.8279, Val Hamming Loss: 0.5043\n",
      "Epoch 14/20, Train Loss: 0.4094, Val Loss: 0.8508, Val Hamming Loss: 0.4929\n",
      "Epoch 15/20, Train Loss: 0.3822, Val Loss: 0.8838, Val Hamming Loss: 0.5014\n",
      "Epoch 16/20, Train Loss: 0.3598, Val Loss: 0.9046, Val Hamming Loss: 0.5014\n",
      "Epoch 17/20, Train Loss: 0.3422, Val Loss: 0.9313, Val Hamming Loss: 0.4843\n",
      "Epoch 18/20, Train Loss: 0.3182, Val Loss: 0.9774, Val Hamming Loss: 0.4957\n",
      "Epoch 19/20, Train Loss: 0.3050, Val Loss: 0.9923, Val Hamming Loss: 0.4843\n",
      "Epoch 20/20, Train Loss: 0.2697, Val Loss: 1.0324, Val Hamming Loss: 0.5014\n",
      "DNN metrics: {'hamming_loss': 0.49714285714285716, 'micro_f1': 0.5583756345177665, 'macro_f1': 0.5441217986131944, 'precision@1': np.float64(0.55), 'precision@3': np.float64(0.53), 'precision@5': np.float64(0.5039999999999999)}\n",
      "\n",
      "Comparing all models:\n",
      "                     hamming_loss  micro_f1  macro_f1  precision@1  \\\n",
      "logistic_regression      0.511429  0.500000  0.497532         0.54   \n",
      "svm                      0.494286  0.523416  0.517744         0.52   \n",
      "perceptron               0.498571  0.511888  0.509035         0.59   \n",
      "online_perceptron        0.524286  0.482370  0.479197         0.54   \n",
      "dnn                      0.497143  0.558376  0.544122         0.55   \n",
      "\n",
      "                     precision@3  precision@5  \n",
      "logistic_regression     0.486667        0.512  \n",
      "svm                     0.503333        0.522  \n",
      "perceptron              0.506667        0.512  \n",
      "online_perceptron       0.470000        0.488  \n",
      "dnn                     0.530000        0.504  \n",
      "All models trained and evaluated!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
